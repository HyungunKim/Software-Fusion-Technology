{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "end2end_starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9sNq7X_YBwg"
      },
      "source": [
        "# 모방학습 기반 자율주행 (실습)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpvaZJue0XFN"
      },
      "source": [
        "## Data 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UusemQuU_kP"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "if not 'data' in os.listdir():\n",
        "    files.upload() #upload kaggle.json\n",
        "    !pip install -q kaggle\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !ls ~/.kaggle\n",
        "    !chmod 600 /root/.kaggle/kaggle.json\n",
        "    !kaggle datasets download -d hyunkunkookminuniv/behavioralcloning\n",
        "    !unzip -q behavioralcloning.zip -d ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XAjNlpP0a_G"
      },
      "source": [
        "## 필수 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO9SjCj8RnqR"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import notebook\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm2oNlCSWEj6"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.layers import Dense, Input, Activation, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization,Add,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import LeakyReLU, ReLU, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose, UpSampling2D, concatenate\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0eUsNz8YHJK"
      },
      "source": [
        "# 실습 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AEv-gGM5Mj3"
      },
      "source": [
        "df = pd.read_csv('/content/data/data1/log.csv')\n",
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TnfNN7e9FRx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDcFKMlC9o7f"
      },
      "source": [
        "plt.plot(df.steer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8cZu_k5Vm-M"
      },
      "source": [
        "log_df1 = pd.read_csv('/content/data/data1/log.csv')\n",
        "log_df2 = pd.read_csv('/content/data/data2/log.csv')\n",
        "log_df3 = pd.read_csv('/content/data/data3/log.csv')\n",
        "log_df4 = pd.read_csv('/content/data/data4/log.csv')\n",
        "\n",
        "logs = [log_df1, log_df2, log_df3, log_df4]\n",
        "\n",
        "for i in range(len(logs)):\n",
        "    logs[i] = 10*logs[i]['steer'].values\n",
        "    \n",
        "    logs[i][logs[i] > 1] = 1.0\n",
        "    logs[i][logs[i] < -1] = -1.0\n",
        "    logs[i] += 1\n",
        "    logs[i] /= 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swtPhzHgmagM"
      },
      "source": [
        "plt.plot(logs[0])\n",
        "plt.xlabel(\"time (s)\")\n",
        "plt.ylabel(\"control value\")\n",
        "plt.title(\"steering control\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VhET1yMi25n"
      },
      "source": [
        "# 인공 신경망 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2sG1brkpTF"
      },
      "source": [
        "class Autonomous_Model(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2D(24, 5, padding='valid')\n",
        "        self.mp1 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')\n",
        "        \n",
        "        self.conv2 = Conv2D(36, 5, padding='valid')\n",
        "        self.mp2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')\n",
        "        \n",
        "        self.conv3 = Conv2D(48, 5, padding='valid')\n",
        "        self.mp3 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')\n",
        "\n",
        "        self.conv4 = Conv2D(64, 3, padding='valid')\n",
        "        self.mp4 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')\n",
        "\n",
        "        self.conv5 = Conv2D(64, 3, padding='valid')\n",
        "        self.mp5 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "        self.d1 = Dense(1164)\n",
        "\n",
        "        self.d2 = Dense(100)\n",
        "\n",
        "        self.d3 = Dense(50)\n",
        "\n",
        "        self.d4 = Dense(10)\n",
        "\n",
        "        self.d5 = Dense(1)\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, *args, **kwargs):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.mp1(x)\n",
        "\n",
        "        return tf.keras.activations.sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi3eVr-7XIHW"
      },
      "source": [
        "Steer_model = Autonomous_Model()\n",
        "\n",
        "Steer_model.compile(optimizer='Adam', loss = 'BCE',  metrics=['mae'])\n",
        "Steer_model.build(input_shape=(None, 256,512,3))\n",
        "Steer_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tgjHVzAmhZ6"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGx-NU9rDAIN"
      },
      "source": [
        "class steer_loader(Sequence):\n",
        "    def __init__(self, img_path, labels, batch_size = 16, shuffle = False, flip=False, bias=0, shift=False, rotate=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_path = img_path\n",
        "        self.img_list_c = sorted(os.listdir(self.img_path+\"center/rgb/\"))\n",
        "        self.img_list_l = sorted(os.listdir(self.img_path+\"left/rgb/\"))\n",
        "        self.img_list_r = sorted(os.listdir(self.img_path+\"right/rgb/\"))\n",
        "        self.labels = labels\n",
        "        self.dataset_size = len(self.img_list_c)\n",
        "        self.shuffle = shuffle\n",
        "        self.flip = flip\n",
        "        self.on_epoch_end()\n",
        "        self.bias = bias\n",
        "        self.shift = shift\n",
        "        self.rotate = rotate\n",
        "        \n",
        "    def __len__(self):\n",
        "\n",
        "        return int(np.floor(self.dataset_size) / self.batch_size)\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(self.dataset_size)\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        cur_batch_name_list = [self.img_list_c[k] for k in indexes]\n",
        "        label_list = np.array([self.labels[k] for k in indexes])\n",
        "        \n",
        "        data_list = []\n",
        "        for i, data in enumerate(cur_batch_name_list):\n",
        "            if self.shift:\n",
        "                img_from = np.random.choice([\"center/rgb/\", \"left/rgb/\", \"right/rgb/\"])\n",
        "            else:\n",
        "                img_from = \"center/rgb/\"\n",
        "            if img_from == \"left/rgb/\":\n",
        "                label_list[i] += self.bias\n",
        "                data = self.img_list_l[indexes[i]]\n",
        "            if img_from == \"right/rgb/\":\n",
        "                label_list[i] -= self.bias\n",
        "                data = self.img_list_r[indexes[i]]\n",
        "\n",
        "            img_data = np.array(image.img_to_array(Image.open(self.img_path + img_from + data)))/255\n",
        "            img_data = img_data[:,:,:3]\n",
        "\n",
        "            \n",
        "            if self.flip and np.random.uniform() > 0.5:\n",
        "                img_data = img_data[:,::-1,:]\n",
        "                label_list[i] = 1 - label_list[i]\n",
        "\n",
        "\n",
        "            data_list.append(img_data)\n",
        "        data_list = np.array(data_list)\n",
        "        data_list = tf.convert_to_tensor(data_list, dtype=tf.float32)\n",
        "        return data_list , label_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha6BUHhH0fs0"
      },
      "source": [
        "train_loader1 =  steer_loader('/content/data/data1/', logs[0],flip=True, shift=True, bias=0.05, rotate=False)\n",
        "train_loader2 =  steer_loader('/content/data/data2/', logs[1],flip=True, shift=True, bias=0.05, rotate=False)\n",
        "train_loader3 =  steer_loader('/content/data/data3/', logs[2],flip=False, bias=0.05, rotate=False)\n",
        "\n",
        "val_loader = steer_loader('/content/data/data3/', logs[2],flip=True)\n",
        "\n",
        "test_loader = steer_loader('/content/data/data4/', logs[3], shuffle = False, flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUnq6tHxDX-x"
      },
      "source": [
        "imgs, labels = train_loader1.__getitem__(2)\n",
        "\n",
        "i = 10\n",
        "plt.imshow(imgs[i])\n",
        "plt.title(f\"steering: {labels[i]:.2f}\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(imgs[i][:,::-1,:])\n",
        "plt.title(f\"steering: {1 - labels[i]:.2f}\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIAXIpLoKF6G"
      },
      "source": [
        "i = 10\n",
        "plt.imshow(imgs[i])\n",
        "plt.title(f\"steering: {labels[i]:.2f}\")\n",
        "plt.show()\n",
        "plt.imshow(imgs[i][:,::-1,:])\n",
        "plt.title(f\"steering: {1 - labels[i]:.2f}\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKq87bL6bEL"
      },
      "source": [
        "# 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjgTZWYb0f0H"
      },
      "source": [
        "for i in range(3):\n",
        "    Steer_model.fit(train_loader1, validation_data = val_loader, epochs=1)\n",
        "\n",
        "    Steer_model.fit(train_loader2, validation_data = val_loader, epochs=1)\n",
        "\n",
        "    Steer_model.fit(train_loader3, validation_data = val_loader, epochs=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCShaw4Z0f9l"
      },
      "source": [
        "test_loader = steer_loader('/content/data/data3/', logs[2], shuffle = False, flip=False)\n",
        "target = []\n",
        "pred = []\n",
        "a = 0\n",
        "for data, label in notebook.tqdm(test_loader):\n",
        "    y_pred = Steer_model(data)\n",
        "    for i, j in zip(label, y_pred):\n",
        "        target.append(i)\n",
        "        pred.append(j)\n",
        "\n",
        "    a += 1\n",
        "# before 1 epoch\n",
        "time_idx = np.arange(len(target))\n",
        "plt.plot(time_idx, target, time_idx, pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}